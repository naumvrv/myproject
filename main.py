# main.py
import os
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

import asyncio
import ccxt.async_support as ccxt_async
import pandas as pd
import numpy as np
import pickle
import sys
import platform
import tensorflow as tf
import warnings
from typing import Dict, List, Optional, Tuple, Any
import aiohttp
import logging

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å –±–∞–∑–æ–≤—ã–º –ª–æ–≥–≥–µ—Ä–æ–º
try:
    from logging_setup import setup_logging
    logger = setup_logging("main_log.txt")
except ImportError as e:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("main")
    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å logging_setup: {e}")

try:
    from config_loader import API_KEY, API_SECRET, API_PASSPHRASE, TESTNET, SYMBOLS, LOG_FILE, FRED_API_KEY
    from dynamic_config import dynamic_config, LEVERAGE, LOOKBACK, initialize_config
    from cache_manager import init_cache
    from data_store import DataStore
    from grok3_analyze import grok3_analyze
    from trading_models import TradingModels
    from trade_executor import TradeExecutor
    from telegram_handler import TelegramHandler
    from feature_engineer import FeatureEngineer
    from logger import log_trade, trade_logger, initialize_logger
    from generate_report import auto_generate_reports
    from data_utils import validate_and_notify
    from sklearn.preprocessing import MinMaxScaler
    from telegram_utils import send_async_message
except ImportError as e:
    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {e}")
    async def send_async_message(msg: str, **kwargs) -> bool:
        logger.warning(f"Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã: {msg}")
        return False
    raise SystemExit(1)

warnings.filterwarnings("ignore", category=DeprecationWarning)
tf.get_logger().setLevel("ERROR")

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

async def fetch_fred_data(series_id: str = "FEDFUNDS", retries: int = 3, delay: int = 5) -> float:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö FRED (—Å—Ç–∞–≤–∫–∞ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ —Ñ–æ–Ω–¥–∞).

    Args:
        series_id (str): –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–µ—Ä–∏–∏ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "FEDFUNDS").
        retries (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3).
        delay (int): –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5).

    Returns:
        float: –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç–∞–≤–∫–∞ FRED –∏–ª–∏ 0.0 –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    if not isinstance(series_id, str) or not series_id:
        logger.error(f"series_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω–æ {series_id}")
        return 0.0
    if not isinstance(retries, int) or retries < 0:
        logger.error(f"retries –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω–æ {retries}")
        retries = 3
    if not isinstance(delay, int) or delay < 0:
        logger.error(f"delay –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω–æ {delay}")
        delay = 5

    for attempt in range(retries):
        try:
            url = f"https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={FRED_API_KEY}&file_type=json"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    response.raise_for_status()
                    data = await response.json()
                    if not isinstance(data, dict) or "observations" not in data:
                        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç API FRED: {data}")
                    latest_rate = float(data["observations"][-1]["value"])
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç–∞–≤–∫–∞ FRED FEDFUNDS: {latest_rate}")
                    return latest_rate
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö FRED (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{retries}): {e}", exc_info=True)
            if attempt == retries - 1:
                await send_async_message(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ FRED –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫")
                return 0.0
            await asyncio.sleep(delay)

async def initialize_exchange() -> ccxt_async.Exchange:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∏—Ä–∂–∏ OKX.

    Returns:
        ccxt_async.Exchange: –û–±—ä–µ–∫—Ç –±–∏—Ä–∂–∏.

    Raises:
        Exception: –ï—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å.
    """
    logger.info("–ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏—Ä–∂–∏ OKX")
    exchange = ccxt_async.okx({
        "apiKey": API_KEY,
        "secret": API_SECRET,
        "password": API_PASSPHRASE,
        "enableRateLimit": True,
        "options": {"defaultType": "swap", "testnet": TESTNET},
    })
    try:
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–∫–æ–≤ OKX")
        await exchange.load_markets()
        logger.info("–ë–∏—Ä–∂–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return exchange
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏—Ä–∂–∏: {e}", exc_info=True)
        raise

async def initialize_models(data_store: DataStore, feature_engineer: FeatureEngineer, 
                            exchange: ccxt_async.Exchange, models_dict_path: str) -> Dict[str, Tuple[TradingModels, pd.DataFrame, MinMaxScaler, int]]:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.

    Args:
        data_store (DataStore): –û–±—ä–µ–∫—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö.
        feature_engineer (FeatureEngineer): –û–±—ä–µ–∫—Ç –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        exchange (ccxt_async.Exchange): –û–±—ä–µ–∫—Ç –±–∏—Ä–∂–∏.
        models_dict_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π.

    Returns:
        Dict[str, Tuple[TradingModels, pd.DataFrame, MinMaxScaler, int]]: –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤.
    """
    if not isinstance(data_store, DataStore):
        logger.error(f"data_store –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º DataStore, –ø–æ–ª—É—á–µ–Ω–æ {type(data_store)}")
        return {}
    if not isinstance(feature_engineer, FeatureEngineer):
        logger.error(f"feature_engineer –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º FeatureEngineer, –ø–æ–ª—É—á–µ–Ω–æ {type(feature_engineer)}")
        return {}
    if not isinstance(exchange, ccxt_async.Exchange):
        logger.error(f"exchange –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º ccxt_async.Exchange, –ø–æ–ª—É—á–µ–Ω–æ {type(exchange)}")
        return {}
    if not isinstance(models_dict_path, str) or not models_dict_path:
        logger.error(f"models_dict_path –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω–æ {models_dict_path}")
        return {}

    logger.info("–ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π")
    models_dict = {}
    if os.path.exists(models_dict_path):
        try:
            with open(models_dict_path, "rb") as f:
                models_dict = pickle.load(f)
            logger.info("–ú–æ–¥–µ–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}", exc_info=True)

    min_data_size = LOOKBACK + 26
    for symbol in SYMBOLS:
        if symbol not in models_dict:
            logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
            await data_store.initial_data_fetch(symbol)
            ohlcv, additional_data = data_store.get_data_for_feature_engineering(symbol)
            is_valid, validated_df = await validate_and_notify(ohlcv, symbol, min_data_size)
            if not is_valid:
                continue

            features_dict = feature_engineer.prepare_features({symbol: validated_df}, [symbol], {symbol: additional_data})
            if symbol not in features_dict:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {symbol}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            X, y, df, scaler_y = features_dict[symbol]
            if X.shape[0] < min_data_size:
                logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è {symbol}: {X.shape[0]} < {min_data_size}")
                continue

            balance_response = await exchange.fetch_balance()
            balance = float(balance_response.get("total", {}).get("USDT", 0))
            grok_analysis = await grok3_analyze(df["close"].iloc[-1], {
                "volatility": df["volatility"].iloc[-1] if "volatility" in df else 0,
                "rsi": df["rsi"].iloc[-1] if "rsi" in df else 50,
                "macd": df["macd"].iloc[-1] if "macd" in df else 0,
                "adx": df["adx"].iloc[-1] if "adx" in df else 25,
                "atr": df["atr"].iloc[-1] if "atr" in df else 0,
                "ichimoku_tenkan": df.get("ichimoku_tenkan", pd.Series([0])).iloc[-1],
                "ichimoku_kijun": df.get("ichimoku_kijun", pd.Series([0])).iloc[-1]
            })
            fred_rate = await fetch_fred_data()

            X_expanded = np.array(X, dtype=np.float32)
            if X_expanded.shape[0] == 0 or np.any(np.isnan(X_expanded)):
                logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}, –ø—Ä–æ–ø—É—Å–∫")
                continue

            num_features = X.shape[2]
            input_features = num_features + 2
            X_expanded = np.pad(X_expanded, ((0, 0), (0, 0), (0, 2)), mode="constant")
            X_expanded[:, :, num_features] = balance
            X_expanded[:, :, num_features + 1] = fred_rate

            models = TradingModels(lookback=X.shape[1], input_features=input_features)
            await models.train_model(X_expanded, y, volatility=df["volatility"].iloc[-1] if "volatility" in df else 0)
            models_dict[symbol] = (models, df, scaler_y, X.shape[1])
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            with open(models_dict_path, "wb") as f:
                pickle.dump(models_dict, f)

    logger.info("–ú–æ–¥–µ–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    return models_dict

async def trading_cycle(symbol: str, data_store: DataStore, executor: TradeExecutor, 
                        feature_engineer: FeatureEngineer, models_dict: Dict, exchange: ccxt_async.Exchange) -> None:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–æ—Ä–≥–æ–≤—ã–π —Ü–∏–∫–ª –¥–ª—è —Å–∏–º–≤–æ–ª–∞.

    Args:
        symbol (str): –°–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, "BTC/USDT:USDT").
        data_store (DataStore): –û–±—ä–µ–∫—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö.
        executor (TradeExecutor): –û–±—ä–µ–∫—Ç –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è —Å–¥–µ–ª–æ–∫.
        feature_engineer (FeatureEngineer): –û–±—ä–µ–∫—Ç –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        models_dict (Dict): –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π.
        exchange (ccxt_async.Exchange): –û–±—ä–µ–∫—Ç –±–∏—Ä–∂–∏.
    """
    if not isinstance(symbol, str) or symbol not in SYMBOLS:
        logger.error(f"symbol –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–∑ SYMBOLS, –ø–æ–ª—É—á–µ–Ω–æ {symbol}")
        return
    if not isinstance(data_store, DataStore):
        logger.error(f"data_store –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º DataStore, –ø–æ–ª—É—á–µ–Ω–æ {type(data_store)}")
        return
    if not isinstance(executor, TradeExecutor):
        logger.error(f"executor –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º TradeExecutor, –ø–æ–ª—É—á–µ–Ω–æ {type(executor)}")
        return
    if not isinstance(feature_engineer, FeatureEngineer):
        logger.error(f"feature_engineer –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º FeatureEngineer, –ø–æ–ª—É—á–µ–Ω–æ {type(feature_engineer)}")
        return
    if not isinstance(models_dict, dict):
        logger.error(f"models_dict –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –ø–æ–ª—É—á–µ–Ω–æ {type(models_dict)}")
        return
    if not isinstance(exchange, ccxt_async.Exchange):
        logger.error(f"exchange –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º ccxt_async.Exchange, –ø–æ–ª—É—á–µ–Ω–æ {type(exchange)}")
        return

    try:
        min_data_size = LOOKBACK + 26
        logger.info(f"–ù–∞—á–∞–ª–æ —Ü–∏–∫–ª–∞ –¥–ª—è {symbol}")
        interval = await data_store.adjust_interval(symbol)
        await data_store.fetch_and_update_data(symbol, interval)
        ohlcv, additional_data = data_store.get_data_for_feature_engineering(symbol)
        is_valid, validated_df = await validate_and_notify(ohlcv, symbol, min_data_size)
        if not is_valid:
            return

        balance_response = await exchange.fetch_balance()
        balance = float(balance_response.get("total", {}).get("USDT", 0))
        await dynamic_config.update_dynamic_params(validated_df["close"].pct_change().std(), balance)

        if symbol not in models_dict:
            logger.warning(f"–ú–æ–¥–µ–ª—å –¥–ª—è {symbol} –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫")
            return
        models, _, _, _ = models_dict[symbol]
        features_dict = feature_engineer.prepare_features(
            {symbol: validated_df}, [symbol], {symbol: additional_data}, 
            interval_minutes=15, strategy="trend", rl_model=models, state=validated_df.tail(LOOKBACK).values
        )
        if symbol not in features_dict:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {symbol} –≤ —Ü–∏–∫–ª–µ")
            return
        X, y, df, scaler_y = features_dict[symbol]
        if X.shape[0] < min_data_size:
            logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è {symbol}: {X.shape[0]} < {min_data_size}")
            return

        grok_analysis = await grok3_analyze(df["close"].iloc[-1], {
            "volatility": df["volatility"].iloc[-1] if "volatility" in df else 0,
            "rsi": df["rsi"].iloc[-1] if "rsi" in df else 50,
            "macd": df["macd"].iloc[-1] if "macd" in df else 0,
            "adx": df["adx"].iloc[-1] if "adx" in df else 25,
            "atr": df["atr"].iloc[-1] if "atr" in df else 0,
            "ichimoku_tenkan": df.get("ichimoku_tenkan", pd.Series([0])).iloc[-1],
            "ichimoku_kijun": df.get("ichimoku_kijun", pd.Series([0])).iloc[-1]
        })
        fred_rate = await fetch_fred_data()

        X_expanded = np.array(X, dtype=np.float32)
        if X_expanded.shape[0] == 0 or np.any(np.isnan(X_expanded)):
            logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –≤ —Ü–∏–∫–ª–µ, –ø—Ä–æ–ø—É—Å–∫")
            return

        num_features = X.shape[2]
        input_features = num_features + 2
        X_expanded = np.pad(X_expanded, ((0, 0), (0, 0), (0, 2)), mode="constant")
        X_expanded[:, :, num_features] = balance
        X_expanded[:, :, num_features + 1] = fred_rate

        models, _, scaler_y, model_lookback = models_dict[symbol]
        current_lookback = X.shape[1]
        if current_lookback != model_lookback:
            logger.info(f"Lookback –¥–ª—è {symbol} –∏–∑–º–µ–Ω–∏–ª—Å—è —Å {model_lookback} –Ω–∞ {current_lookback}")
            models = TradingModels(lookback=current_lookback, input_features=input_features)
            await models.train_model(X_expanded, y, volatility=df["volatility"].iloc[-1] if "volatility" in df else 0)
            models_dict[symbol] = (models, df, scaler_y, current_lookback)

        state = X_expanded[-1:]
        current_price = (await exchange.fetch_ticker(symbol))["last"]
        await executor.check_open_positions(symbol, current_price)

        action_idx = models.get_action(state[0], volatility=df["volatility"].iloc[-1] if "volatility" in df else 0, sentiment=grok_analysis["sentiment"])
        action_map = {
            0: "hold", 1: "buy_long", 2: "sell_short", 3: "increase_amount",
            4: "decrease_amount", 5: "grid_buy", 6: "grid_sell", 7: "arbitrage"
        }
        action = action_map.get(action_idx, "hold")

        predicted_change_normalized = float(models.predict(state)[0][0])
        predicted_change_denormalized = scaler_y.inverse_transform([[predicted_change_normalized]])[0][0]
        adjusted_change = grok_analysis["predicted_change"]
        predicted_price = current_price + adjusted_change

        if action in ["buy_long", "sell_short", "grid_buy", "grid_sell"] and executor.positions[symbol] is None:
            await executor.execute_trade(
                action, current_price, grok_analysis, predicted_price, 
                log_trade, symbol=symbol, atr=df["atr"].iloc[-1], rsi=df["rsi"].iloc[-1], fred_rate=fred_rate
            )
            
            next_ohlcv, _ = data_store.get_data_for_feature_engineering(symbol)
            if not next_ohlcv.empty and len(next_ohlcv) >= min_data_size:
                next_features_dict = feature_engineer.prepare_features(
                    {symbol: next_ohlcv}, [symbol], {symbol: additional_data}, 
                    interval_minutes=15, strategy="trend", rl_model=models, state=next_ohlcv.tail(LOOKBACK).values
                )
                if symbol in next_features_dict:
                    next_X, _, next_df, _ = next_features_dict[symbol]
                    next_X_expanded = np.array(next_X, dtype=np.float32)
                    next_X_expanded = np.pad(next_X_expanded, ((0, 0), (0, 0), (0, 2)), mode="constant")
                    next_X_expanded[:, :, num_features] = balance
                    next_X_expanded[:, :, num_features + 1] = fred_rate
                    next_state = next_X_expanded[-1:]
                    current_price = (await exchange.fetch_ticker(symbol))["last"]
                    profit = ((next_df["close"].iloc[-1] - df["close"].iloc[-1]) * executor.amounts[symbol] * executor.leverage 
                             if action in ["buy_long", "grid_buy"] else 
                             (df["close"].iloc[-1] - next_df["close"].iloc[-1]) * executor.amounts[symbol] * executor.leverage)
                    actual_change = next_df["close"].iloc[-1] - df["close"].iloc[-1]
                    reward = profit / current_price if current_price != 0 else 0
                    done = executor.positions[symbol] is None
                    await log_trade(symbol, action, df["close"].iloc[-1], profit, grok_analysis, predicted_price, actual_change)
                    models.store_transition(state[0], action_idx, reward, next_state[0], done)
                    if len(models.memory) >= models.batch_size * 2:
                        models.replay()

        elif action in ["increase_amount", "decrease_amount"]:
            current_amount = executor.amounts[symbol]
            new_amount = current_amount * 1.1 if action == "increase_amount" else current_amount * 0.9
            executor.amounts[symbol] = new_amount
            await log_trade(symbol, action, current_price, None)

        if await models.should_retrain():
            await models.train_model(X_expanded, y, volatility=df["volatility"].iloc[-1] if "volatility" in df else 0)
            models_dict[symbol] = (models, df, scaler_y, current_lookback)
            logger.info(f"–ú–æ–¥–µ–ª—å –¥–ª—è {symbol} –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ç–æ—Ä–≥–æ–≤–æ–º —Ü–∏–∫–ª–µ –¥–ª—è {symbol}: {e}", exc_info=True)

async def main() -> None:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±–æ—Ç–∞."""
    logger.info("–ù–∞—á–∞–ª–æ main()")
    try:
        await initialize_config()
        logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ initialize_config: {e}", exc_info=True)
        raise
    
    start_time = asyncio.get_event_loop().time()
    max_attempts = 5
    models_dict_path = "models_dict_state.pkl"
    attempt = 0
    telegram_handler = None
    exchange = None

    while attempt < max_attempts:
        try:
            logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
            await init_cache()
            logger.info("–ö—ç—à –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            await initialize_logger()
            logger.info("–õ–æ–≥–≥–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            exchange = await initialize_exchange()
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataStore")
            data_store = DataStore(exchange, SYMBOLS.keys())
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TelegramHandler")
            telegram_handler = TelegramHandler(None, exchange)
            telegram_handler.set_start_time(start_time)
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TradeExecutor")
            executor = TradeExecutor(exchange, telegram_handler)
            telegram_handler.executor = executor
            logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FeatureEngineer")
            feature_engineer = FeatureEngineer()

            logger.info("–ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π")
            models_dict = await initialize_models(data_store, feature_engineer, exchange, models_dict_path)
            logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –∑–∞–ø—É—Å–∫–µ")
            await send_async_message("‚úÖ –ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")
            logger.info("–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")

            attempt = 0
            report_task = asyncio.create_task(auto_generate_reports())
            while True:
                if telegram_handler.paused:
                    logger.info("–ë–æ—Ç –Ω–∞ –ø–∞—É–∑–µ")
                    await asyncio.sleep(60)
                    continue
                
                cycle_start = asyncio.get_event_loop().time()
                tasks = [trading_cycle(symbol, data_store, executor, feature_engineer, models_dict, exchange) 
                         for symbol in SYMBOLS]
                await asyncio.gather(*tasks)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
                with open(models_dict_path, "wb") as f:
                    pickle.dump(models_dict, f)
                logger.info("–°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞")

                cycle_duration = asyncio.get_event_loop().time() - cycle_start
                if cycle_duration > 120:
                    await send_async_message(f"‚ö†Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ —Ü–∏–∫–ª–∞: {cycle_duration:.2f} —Å–µ–∫—É–Ω–¥")
                await asyncio.sleep(max(15 - cycle_duration, 1))

        except Exception as e:
            attempt += 1
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}): {e}", exc_info=True)
            escaped_error = str(e).replace("(", "\\(").replace(")", "\\)").replace("-", "\\-")
            if telegram_handler:
                await send_async_message(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ \\(–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}\\): {escaped_error}")
            else:
                logger.warning("TelegramHandler –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            if attempt >= max_attempts:
                logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
                try:
                    with open(models_dict_path, "wb") as f:
                        pickle.dump(models_dict, f)
                    logger.info("–°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
                    await trade_logger.close()
                    if telegram_handler:
                        telegram_handler.stop_polling()
                        await asyncio.sleep(1)
                    if exchange:
                        await exchange.close()
                        logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∏—Ä–∂–µ–π –∑–∞–∫—Ä—ã—Ç–æ")
                    if 'report_task' in locals():
                        report_task.cancel()
                        await asyncio.sleep(1)
                except Exception as shutdown_e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {shutdown_e}", exc_info=True)
                sys.exit(1)
            delay = min(300 * (2 ** (attempt - 1)), 3600)
            if telegram_handler:
                telegram_handler.stop_polling()
                await asyncio.sleep(1)
            if exchange:
                await exchange.close()
                logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∏—Ä–∂–µ–π –∑–∞–∫—Ä—ã—Ç–æ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º")
            await asyncio.sleep(delay)
            logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞...")

if __name__ == "__main__":
    asyncio.run(main())